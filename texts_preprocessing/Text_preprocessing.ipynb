{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первая версия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите полный путь к файлу: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# installations: docx2txt, pdf.miner.six\n",
    "# author: Terekhina Maria\n",
    "\n",
    "import docx2txt\n",
    "import io\n",
    "import re\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "\n",
    "def remove_ending(text):\n",
    "    '''\n",
    "    Remove bibliography.\n",
    "    '''\n",
    "    text = re.sub('(Литература|Список( использованной)? литературы|Библиография)(\\.)?.*', '', text, flags=re.S)\n",
    "    return text\n",
    "\n",
    "def remove_begining(text):\n",
    "    '''\n",
    "    Remove all before introduction\n",
    "    '''\n",
    "    text = re.sub('.*?Введение(\\.)?', 'Введение', text, flags=re.S)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Remove page numbers and system symbols\n",
    "    '''\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    text = re.sub('\\f', '\\n', text)\n",
    "    text = re.sub('\\n+( )*[0-9]+( )*\\n+', '', text)\n",
    "    text = remove_begining(text)\n",
    "    text = remove_ending(text)\n",
    "    return text\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    '''\n",
    "    Convert pdf to plain text\n",
    "    '''\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return clean_text(text)\n",
    "\n",
    "def document_to_text(path):\n",
    "    '''\n",
    "    Choose a convertor for the file: pdf or docx\n",
    "    '''\n",
    "    if path[-5:] == \".docx\":\n",
    "        text = docx2txt.process(path)\n",
    "        return clean_text(text)\n",
    "    elif path[-4:] == \".pdf\":\n",
    "        return convert_pdf_to_txt(path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(document_to_text(input('Введите полный путь к файлу: ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вторая версия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installations: docx2txt, pdf.miner.six\n",
    "# author: Evgenii Glazunov\n",
    "\n",
    "import docx2txt\n",
    "import io\n",
    "import re\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "\n",
    "def remove_ending(text):\n",
    "    '''\n",
    "    Remove bibliography.\n",
    "    '''\n",
    "    reg = re.compile('(Литература|Список( использованной)? литературы|Библиография).*', re.DOTALL)\n",
    "    text = reg.sub('', text, re.DOTALL)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_begining(text):\n",
    "    '''\n",
    "    Remove all before introduction\n",
    "    '''\n",
    "    text = re.sub('.*?Введение(\\.)?', '', text, flags=re.S)\n",
    "    return text\n",
    "\n",
    "def remove_content(text):\n",
    "    text = remove_begining(text)\n",
    "    text = remove_ending(text)\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_symbols(text):\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    text = re.sub('\\f', '\\n', text)\n",
    "    text = re.sub('\\n+( )*[0-9]+( )*\\n+', '', text)\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    #text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Remove page numbers and system symbols\n",
    "    '''\n",
    "    text = remove_content(text)\n",
    "    text = remove_symbols(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    '''\n",
    "    Convert pdf to plain text\n",
    "    '''\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams(char_margin=20)\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n",
    "                                  password=password,\n",
    "                                  caching=caching,\n",
    "                                  check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n",
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate ()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "\n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "    \n",
    "def document_to_text(path):\n",
    "    '''\n",
    "    Choose a convertor for the file: pdf or docx\n",
    "    '''\n",
    "    if path[-5:] == \".docx\":\n",
    "        text = docx2txt.process(path)\n",
    "    elif path[-4:] == \".doc\":\n",
    "        save_as_docx(path)\n",
    "        os.remove(path)\n",
    "        text = docx2txt.process(path+'x')\n",
    "    elif path[-4:] == \".pdf\":\n",
    "        text = convert_pdf_to_txt(path)\n",
    "    elif path[-4:] == '.txt':\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "    return clean_text(text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_special(line):\n",
    "    if re.match('^([0-9]+\\.)+\\s{,3}.*?', line): return True\n",
    "    elif re.match('^\\([0-9]\\)+\\s{,3}.*?', line): return True\n",
    "    #elif re.match('^(Рис|Таб)\\.\\s{0,3}\\d{1,3}\\.?\\s{1,2}[A-ZА-Я].*?$', paragraph): return True\n",
    "    else: return False\n",
    "\n",
    "def _not_finished(line, length):\n",
    "    line = line.strip()\n",
    "    l = len(line)\n",
    "    if line:\n",
    "        if re.match('^.*?\\W\\w{1,2}\\.$', line): return True\n",
    "        elif line[-1] in '.?!…': return False\n",
    "        else: return True\n",
    "    else: return True\n",
    "    \n",
    "def _to_be_merged(line, last_array, previous, length):\n",
    "    len1 = len(line.strip())\n",
    "    len0 = len(previous.strip())\n",
    "    if (not _is_special(line) or re.match('^[0-9.) ]*$', line.strip())) and _not_finished(last_array, length):\n",
    "        if len0 >= 0.8*len1 and len0 > 0.6*length: return True\n",
    "        elif re.match('^Таб.\\s{,3}[0-9].*?', last_array) and len1 < 0.75*length: return True\n",
    "        else: return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lines(text):\n",
    "    text = text.split('\\n')\n",
    "    length = max(len(i) for i in text)\n",
    "    new = []\n",
    "    for key, value in enumerate(text):\n",
    "        line = value.strip()\n",
    "        #print (key, '|',line,'|')\n",
    "        if not new: new.append(line)\n",
    "        else:\n",
    "            if _to_be_merged(line, new[-1], text[key-1], length): new[-1] = new[-1] + line + ' '\n",
    "            else: new.append(line+' ')\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_be_deleted(paragraph):\n",
    "    if re.match('^(\\([0-9]*?\\)|([0-9]+\\.){1,}[0-9]+) .*?$', paragraph): return True\n",
    "    elif re.match('^(Рис|Таб)\\.\\s{0,3}\\d{1,3}\\..*?$', paragraph): return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_to_text('D:/DATA/Test/1.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = document_to_text('D:/DATA/Test/1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = document_to_text('essay.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in merge_lines(x):\n",
    "    if not _to_be_deleted(paragraph): print (paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таб. 1. Коллекции текстов, используемые для сравнения Коллекция  Источник  Формат  Размер коллекции Толстой  Оцифрованное тексты  4.2 млн собрание сочинений НКРЯ  Коллекция текстов из тексты  64 млн НКРЯ Araneum  Araneum Russicum обученная модель, 10 млрд Maximum доступная на ресурсе RusVectores \n",
      "2.1 Обработка текста \n",
      "2.1.1 Извлечение текста \n",
      "2.1.2  Нормализация текста \n",
      "2.1.3 Разделение на предложения \n",
      "2.1.4 Лемматизация \n",
      "2.1.5 Объединение в файл для обучения модели \n",
      "2.2 Векторные модели \n",
      "2.2.1 Технологии \n",
      "2.2.2 Алгоритмы \n",
      "2.2.3 Параметры \n",
      "3.1 Оценка качества моделей \n",
      "Таб. 2. Коэффициент Спирмена на тестовой выборке ru_simlex965 Word2Vec  FastText CBOW  Skipgram  CBOW  Skipgram Толстой  -0.02  0.14  0.10  0.16 НКРЯ 19 век  0.27  0.32  0.24  0.28 Araneum 0.32  0.33 \n",
      "3.2 Искусственный сдвиг значения \n",
      "3.3 Метрики \n",
      "3.3.1 Тау Кендалла \n",
      "3.3.2 Коэффициент Жаккара \n",
      "3.3.3 NDCG \n",
      "3.4 Подбор количества соседей для оценки \n",
      "Рис. 2. Коэффициент корреляции Спирмена для коэффициента Жаккара и NDCG для коллекции текстов второй половины 19 века  \n",
      "Таб. 3. Коэффициенты корреляции Пирсона для различных метрик для текстов Л.Н. Толстого Толстой Значение схожести Значение схожести Kendall  Jaccard  NDCG 1.000000  0.308338  0.409485  0.388679 Kendall  0.308338  1.000000  0.857290  0.876627 Jaccard  0.409485  0.857290  1.000000  0.959425 NDCG  0.388679  0.876627  0.959425  1.000000 \n",
      "Таб. 4. Коэффициенты корреляции Пирсона для различных метрик для текстов второй половины 19 века 19 век Реальное значение Реальное значение Kendall  Jaccard  NDCG 1.000000  0.339639  0.468192  0.462985 Kendall  0.339639  1.000000  0.849684  0.876704 Jaccard  0.468192  0.849684  1.000000  0.961458 NDCG  0.462985  0.876704  0.961458  1.000000 \n",
      "3.5 Регрессия \n",
      "3.5.1 Линейная регрессия \n",
      "3.5.2 Полиномиальные данные \n",
      "Таб. 5. Коэффициенты корреляции для значений предсказаний линейной модели на основе полиномиальных признаков  Корпус Степень 1 (лин. модель)  2  3  4 Толстой  0.412201  0.435014  0.457751  0.472014 19 века  0.485232  0.515381  0.537972  0.554274 \n",
      "3.5.3 Перемножение параметров \n",
      "Таб. 6. Сравнение отдельных метрик и искусственной метрики Лучшая метрика  Перемножение коэффициента Жаккара и NDCG Толстой  0.409485  0.413379 19 век  0.468192  0.462479 \n",
      "(1)  Свидетель-городовой на вопросы председателя, обвинителя, защитника безжизненно отрубал: «Так точно-с», «Не могу знать» ― и опять «Так точно…» [Л. Н. Толстой. Воскресение (1899)] \n",
      "(2)  К глубокому огорчению защитника свидетель ничего этого не замечал. [И. Н. Потапенко. Тайна (1892)] \n",
      "(3)  Впервые здесь прошел розыгрыш традиционного Кубка памяти Валерия Спирихина, защитника и капитана команды «Химмаш», скоропостижно скончавшегося в 1982 году в возрасте 30 лет. [Сергей Веткин. Играйте в футбол! (2013.05.17) // «Новгородские ведомости», 2013] \n",
      "4.1 Учет особенностей моделей \n",
      "5.1 Части речи \n",
      "Рис. 3. Доля частей речи в первой и последней доли списка Рис. 4.  Доля частей речи в первой и последней доли списка  \n",
      "5.2 Примеры лексем, отличающих тексты Л. Н. Толстого \n",
      "(4)  Материя есть предел того, что мы считаем собою в пространстве, т.е. вне времени. [Л. Н. Толстой. Записные книжки (1890-1899)] \n",
      "(5)  Женщины одеты в обыкновенное русское платье, и при этом волосы у них закрыты платком или куском материи, свернутым наподобие сахарной головы, со свесившимися назад концами. [В. В. Верещагин. Из путешествий по Закавказскому краю (1899)] \n",
      "(6)  Более того, по мнению ряда теоретиков, именно многочисленные сверххолодные и почти неуловимые коричневые карлики могут на самом деле составлять значительную долю скрытой массы Вселенной ― пресловутой темной материи. [Тигран Оганесян. На Luhman 16B облачно с прояснениями // «Эксперт», 2014] \n",
      "(7)  Что касается славы, то это материя более тонкая и коварная, чем деньги. [Вера Краснова. Поборник Троицы // «Эксперт», 2014] \n",
      "(8)  Материя их платьев обычно выглядит как зеленая парча, хотя Геллена знает, что на самом деле это мох. [Ольга Онойко. Некромантисса (2014)] \n"
     ]
    }
   ],
   "source": [
    "for paragraph in merge_lines(x):\n",
    "    if _to_be_deleted(paragraph): print (paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lines(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
